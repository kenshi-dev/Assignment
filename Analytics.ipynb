{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpYruSBh1O97gC0V6qPKat",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenshi-dev/Assignment/blob/main/Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "def prepare_data_for_modeling(data, target_enroll, target_grad):\n",
        "       \"\"\"Prepares data for modeling.\"\"\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wLZWRX4PdtTg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(filepath=\"student data.csv.csv\"):\n",
        "    \"\"\"Loads and preprocesses data.\"\"\"\n",
        "    data = pd.read_csv(\"https://colab.research.google.com/drive/1alUVH4fEhv3a_YdzsemCcaYU7FnZqw7V#scrollTo=d9jX9YznakXq\")\n",
        "    data = data.fillna(data.mean(40))\n",
        "    return data\n",
        "    return data.fillna(data.mean(40))"
      ],
      "metadata": {
        "id": "tZHd7ahleDr6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_modeling(data, target_enroll, target_grad):\n",
        "    \"\"\"Prepares data for modeling.\"\"\"\n",
        "    X = data.drop([target_enroll, target_grad], axis=1)\n",
        "    y_enroll = data[target_enroll]\n",
        "    y_grad = data[target_grad]\n",
        "    return X, y_enroll, y_grad"
      ],
      "metadata": {
        "id": "wMN1MblYap9c"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pipeline(numerical_features, categorical_features, model):\n",
        "    \"\"\"Scaling and normalization\"\"\"\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='40')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('50', numerical_transformer, numerical_features),\n",
        "            ('37', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('model', model)])\n",
        "    return pipeline"
      ],
      "metadata": {
        "id": "XbOto3XhavfD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(X, y, model, param_grid=None):\n",
        "    \"\"\"Trains and evaluates a model with optional hyperparameter tuning.\"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if param_grid:\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "    else:\n",
        "        best_model = model\n",
        "\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]))\n",
        "    print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def predict_on_new_data(model, new_data):\n",
        "    \"\"\"Makes predictions on new data.\"\"\"\n",
        "    predictions = model.predict(new_data)\n",
        "    return predictions\n",
        "\n",
        "def train_and_evaluate_model(X, y, model, param_grid=None):\n",
        "    \"\"\"Trains and evaluates a model with optional hyperparameter tuning.\"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if param_grid:\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "    else:\n",
        "        best_model = model\n",
        "\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]))\n",
        "    print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def predict_on_new_data(model, new_data):\n",
        "    \"\"\"Makes predictions on new data.\"\"\"\n",
        "    predictions = model.predict(new_data)\n",
        "    return predictions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    filepath = 'student_data_extended.csv'\n",
        "    data = load_and_preprocess_data('student data.csv.csv')\n",
        "    X, y_enroll, y_grad = prepare_data_for_modeling(data, 'Enrolled', 'Graduated')\n",
        "\n",
        "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    enroll_models = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "    }\n",
        "\n",
        "    grad_models = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "    }\n",
        "\n",
        "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    enroll_models = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "    }\n",
        "\n",
        "    grad_models = {\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "Qni_UKv7kGMN",
        "outputId": "d623446a-7528-4939-de16-4f22753826bd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 2 fields in line 10, saw 680\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-45ca7ffeb87b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'student_data_extended.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'student data.csv.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_enroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data_for_modeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Enrolled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Graduated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-ad752c9c0fb8>\u001b[0m in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"student data.csv.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Loads and preprocesses data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://colab.research.google.com/drive/1alUVH4fEhv3a_YdzsemCcaYU7FnZqw7V#scrollTo=d9jX9YznakXq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 10, saw 680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(\"\\nEnrollment Model Evaluations:\")\n",
        "    for model_name, model in enroll_models.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        enroll_pipeline = create_pipeline(numerical_features, categorical_features, model)\n",
        "        train_and_evaluate_model(X, y_enroll, enroll_pipeline)\n"
      ],
      "metadata": {
        "id": "S1de75WGtZLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGraduation Model Evaluations:\")\n",
        "    for model_name, model in grad_models.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        grad_pipeline = create_pipeline(numerical_features, categorical_features, model)\n",
        "        train_and_evaluate_model(X, y_grad, grad_pipeline)\n"
      ],
      "metadata": {
        "id": "-imqBJ1UtzQQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}